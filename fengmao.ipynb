{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import jionlp as jio\n",
    "from openai import OpenAI\n",
    "from http.client import RemoteDisconnected\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_directory = \"./A fengmaoyaosu/yaosu_2/paper_5\"\n",
    "\n",
    "# 获取当前文件夹下的所有PDF文件\n",
    "pdf_files = [file for file in os.listdir(current_directory) if file.endswith('.pdf')]\n",
    "\n",
    "# 保存所有拆分以后的文件夹地址\n",
    "all_folder_paths = []\n",
    "\n",
    "# 创建一个文件夹用于保存每个PDF文件，方便后面往知识库上传\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_filename, _ = os.path.splitext(pdf_file)\n",
    "    folder_name = pdf_filename + '_folder'\n",
    "    folder_path = os.path.join(current_directory, folder_name)\n",
    "\n",
    "    # 创建文件夹\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # 移动PDF文件到文件夹中\n",
    "    shutil.move(os.path.join(current_directory, pdf_file), os.path.join(folder_path, pdf_file))\n",
    "\n",
    "    all_folder_paths.append(folder_path)\n",
    "\n",
    "# 获取 WSL 的 IP 地址\n",
    "wsl_ip = os.popen(\"ip addr show eth0 | grep 'inet ' | awk '{print $2}' | cut -d/ -f1\").read().strip()\n",
    "print(f\"WSL IP Address: {wsl_ip}\")\n",
    "\n",
    "# 初始化结果列表\n",
    "all_results = []\n",
    "\n",
    "# 定义结果文件的路径和文件名\n",
    "output_directory = \"./A fengmaoyaosu/yaosu_2/chouquresults_5\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def save_results_to_file(file_name, results):\n",
    "    output_file_path = os.path.join(output_directory, f\"{file_name}.txt\")\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        for item in results:\n",
    "            file.write(f\"Query: {item['query']}\\n\")\n",
    "            file.write(f\"Answer: {item['res']}\\n\")\n",
    "            file.write(\"\\n\")\n",
    "    print(f\"Results for {file_name} have been saved to {output_file_path}\")\n",
    "\n",
    "def load_processed_files(output_directory):\n",
    "    processed_files = set()\n",
    "    for filename in os.listdir(output_directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            processed_files.add(filename.replace('.txt', ''))\n",
    "    return processed_files\n",
    "\n",
    "# 已处理文件列表\n",
    "processed_files = load_processed_files(output_directory)\n",
    "\n",
    "for folder_path in all_folder_paths:\n",
    "    # 获取当前文件名\n",
    "    file_name = os.path.basename(folder_path).replace('_folder', '')\n",
    "    \n",
    "    # 跳过已处理的文件\n",
    "    if file_name in processed_files:\n",
    "        print(f\"Skipping already processed file: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    # 1.新建知识库，默认一篇PDF为一个知识库，\n",
    "    url = f\"http://{wsl_ip}:8777/api/local_doc_qa/new_knowledge_base\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"user_id\": \"zzp\",  # 用户id，不需要改动\n",
    "        \"kb_name\": file_name,  # 知识库名称，按需修改，暂时用的是论文名称\n",
    "    }\n",
    "\n",
    "    response = None\n",
    "    while not response:\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(data, ensure_ascii=False))\n",
    "            response.raise_for_status()\n",
    "        except RemoteDisconnected:\n",
    "            print(\"Remote server disconnected. Retrying...\")\n",
    "            response = None\n",
    "            time.sleep(5)\n",
    "        except (requests.ConnectionError, requests.Timeout):\n",
    "            response = None\n",
    "            print(\"Connection error or timeout occurred. Retrying...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    print(f\"New Knowledge Base Response: {response.json()}\")\n",
    "\n",
    "    current_kb_id = response.json()['data'][\"kb_id\"]\n",
    "    print(f\"Knowledge Base ID: {current_kb_id}\")\n",
    "\n",
    "    # 2.上传文件\n",
    "    url = f\"http://{wsl_ip}:8777/api/local_doc_qa/upload_files\"\n",
    "    data = {\n",
    "        \"user_id\": \"zzp\",\n",
    "        \"kb_id\": current_kb_id,\n",
    "        \"mode\": \"soft\"\n",
    "    }\n",
    "\n",
    "    files = []\n",
    "    for root, dirs, file_names in os.walk(folder_path):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith(\".pdf\"):  # 这里只上传后缀是pdf的文件，\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                files.append((\"files\", open(file_path, \"rb\")))\n",
    "\n",
    "    response = None\n",
    "    while not response:\n",
    "        try:\n",
    "            response = requests.post(url, files=files, data=data)\n",
    "            response.raise_for_status()\n",
    "        except RemoteDisconnected:\n",
    "            print(\"Remote server disconnected. Retrying...\")\n",
    "            response = None\n",
    "            time.sleep(5)\n",
    "        except (requests.ConnectionError, requests.Timeout):\n",
    "            response = None\n",
    "            print(\"Connection error or timeout occurred. Retrying...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    print(f\"Upload Files Response: {response.json()}\")\n",
    "\n",
    "    # 检查文件解析状态\n",
    "    def check_file_status(file_id, current_kb_id, timeout=120):\n",
    "        url = f\"http://{wsl_ip}:8777/api/local_doc_qa/list_files\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        data = {\n",
    "            \"user_id\": \"zzp\",\n",
    "            \"kb_id\": current_kb_id\n",
    "        }\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "                response.raise_for_status()\n",
    "                file_status = response.json()['data']['details'][0]['status']\n",
    "                print(f\"File Status: {file_status}\")\n",
    "                if file_status == 'green':\n",
    "                    return True\n",
    "                if time.time() - start_time > timeout:\n",
    "                    print(f\"File {file_id} processing timeout. Skipping...\")\n",
    "                    return False\n",
    "                time.sleep(5)  # 等待 5 秒钟后再检查一次\n",
    "            except RemoteDisconnected:\n",
    "                print(\"Remote server disconnected. Retrying...\")\n",
    "                time.sleep(5)\n",
    "            except (requests.ConnectionError, requests.Timeout):\n",
    "                print(\"Connection error or timeout occurred. Retrying...\")\n",
    "                time.sleep(5)\n",
    "\n",
    "    # 获取文件列表（POST）\n",
    "    url = f\"http://{wsl_ip}:8777/api/local_doc_qa/list_files\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"user_id\": \"zzp\",\n",
    "        \"kb_id\": current_kb_id\n",
    "    }\n",
    "\n",
    "    response = None\n",
    "    while not response:\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "            response.raise_for_status()\n",
    "        except RemoteDisconnected:\n",
    "            print(\"Remote server disconnected. Retrying...\")\n",
    "            response = None\n",
    "            time.sleep(5)\n",
    "        except (requests.ConnectionError, requests.Timeout):\n",
    "            response = None\n",
    "            print(\"Connection error or timeout occurred. Retrying...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    print(f\"List Files Response: {response.json()}\")\n",
    "\n",
    "    current_file_id = response.json()['data']['details'][0]['file_id']\n",
    "    print(f\"File ID: {current_file_id}\")\n",
    "\n",
    "    # 检查文件状态，直到文件解析完成或超时\n",
    "    if not check_file_status(current_file_id, current_kb_id):\n",
    "        print(f\"Skipping file {file_name} due to processing timeout.\")\n",
    "        continue\n",
    "\n",
    "    def rag__fengmao_qa(query, current_kb_id):\n",
    "        url = f\"http://{wsl_ip}:8777/api/local_doc_qa/local_doc_chat\"\n",
    "        headers = {\n",
    "            'content-type': 'application/json'\n",
    "        }\n",
    "        data = {\n",
    "            \"user_id\": \"zzp\",\n",
    "            \"kb_ids\": [current_kb_id],\n",
    "            \"question\": query\n",
    "        }\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = None\n",
    "        while not response:\n",
    "            try:\n",
    "                response = requests.post(url=url, headers=headers, json=data, timeout=120, stream=False)\n",
    "                response.raise_for_status()\n",
    "                res = response.json()\n",
    "                print(\"Response JSON:\", json.dumps(res, indent=2, ensure_ascii=False))  # 打印响应内容以检查其结构\n",
    "\n",
    "                if 'history' in res and len(res['history']) > 0:\n",
    "                    # Assuming the answer is in the second item of the first list in 'history'\n",
    "                    answers = res['history'][0][1]\n",
    "                else:\n",
    "                    answers = \"Error: No history found in response.\"\n",
    "            except RemoteDisconnected:\n",
    "                print(\"Remote server disconnected. Retrying...\")\n",
    "                response = None\n",
    "                time.sleep(5)\n",
    "            except (requests.ConnectionError, requests.Timeout):\n",
    "                print(\"Connection error or timeout occurred. Retrying...\")\n",
    "                response = None\n",
    "                time.sleep(5)\n",
    "            except (KeyError, IndexError) as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                answers = \"Error: The response structure is not as expected.\"\n",
    "\n",
    "        return answers\n",
    "\n",
    "    # 定义11个问题\n",
    "    query_list = [\n",
    "        \"假设你是一位城市风貌研究领域专家，对城市风貌研判与塑造有持续深入的研究和贡献，请从文章中总结风貌的“物质形态”构成要素?\",\n",
    "        \"请从文章中总结风貌的“自然环境”构成要素。“自然环境”是指“城市及其周边区域的自然地理特征和生态系统，包括所有未被人类开发或仅部分开发的自然要素”?\",\n",
    "        \"请从文章中总结风貌的“城市空间格局”构成要素。“城市空间格局”是指“指整体性、宏观层面的，涉及整个城市或大区域的空间结构和布局”?\",\n",
    "        \"请从文章中总结风貌的“道路结构”构成要素。“道路结构”是指“相对宏观层级的，涉及整个城市或区域内道路系统的整体组织和连接方式，关注的是道路网络的功能性和交通流动性?\",\n",
    "        \"请从文章中总结风貌的“地块单元形态”构成要素。不同于城市空间格局， “地块单元形态”是指“指微观层面的，涉及具体地块的几何形态和空间分布?\",\n",
    "        \"请从文章中总结风貌的“公共空间”构成要素。“公共空间”是指“城市中供公众日常使用和活动的开放空间的组织和形态特征。它涵盖了城市中所有对公众开放的场所，但我们这里不包括街道空间”?\",\n",
    "        \"请从文章中总结风貌的“街道空间形态”构成要素。不同于道路结构，“街道空间形态”是是相对微观层级的，涉及具体街道及其周边区域的物理特征和设计，关注的是街道的使用体验和视觉效果?\",\n",
    "        \"请从文章中总结风貌的“建筑形态”构成要素。“建筑形态”是指“城市中各类建筑物的外观和结构特征”?\",\n",
    "        \"请从文章中总结风貌的“历史街区形态”构成要素。“历史街区形态”是指“具有历史和文化价值的城市区域的整体空间组织和布局特征，体现特定历史时期的城市风貌”?\",\n",
    "        \"请从文章中总结风貌的“历史建筑形态”构成要素。“历史建筑形态”是指“具有历史和文化价值的单体建筑物的外观和结构特征”?\",\n",
    "        \"请从文章中总结风貌的“历史遗址形态”构成要素。“历史遗址形态”是指“城市内具有考古和历史价值的遗址的空间形态和保存状况，代表特定历史时期的遗存特征?\"\n",
    "    ]\n",
    "\n",
    "    # 获取每个问题的答案\n",
    "    results = []\n",
    "    for query in query_list:\n",
    "        print(f\"Query: {query}\")\n",
    "        answer = rag__fengmao_qa(query=query, current_kb_id=current_kb_id)\n",
    "        print(f\"Answer: {answer}\")\n",
    "        results.append({\"query\": query, \"res\": answer})\n",
    "\n",
    "    # 将当前文件的结果保存到总结果列表\n",
    "    all_results.append({\n",
    "        \"file_name\": file_name,\n",
    "        \"results\": results\n",
    "    })\n",
    "\n",
    "    # 保存当前文件的结果到文件\n",
    "    save_results_to_file(file_name, results)\n",
    "\n",
    "print(f\"Results have been saved to {output_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_result_file(file_path):\n",
    "    \"\"\"\n",
    "    读取单个结果文件，将其内容解析为问答对列表。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read().strip().split('\\n\\n')\n",
    "        result = []\n",
    "        current_query = None\n",
    "        current_answers = []\n",
    "        for section in content:\n",
    "            if section.startswith(\"Query:\"):\n",
    "                if current_query:\n",
    "                    result.append({\"query\": current_query, \"res\": \"\\n\\n\".join(current_answers)})\n",
    "                current_query = section\n",
    "                current_answers = []\n",
    "            elif section.startswith(\"Answer:\") and current_query:\n",
    "                current_answers.append(section)\n",
    "        if current_query:\n",
    "            result.append({\"query\": current_query, \"res\": \"\\n\\n\".join(current_answers)})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_all_results(result_directory):\n",
    "    \"\"\"\n",
    "    从指定目录中加载所有结果文件，并将其内容解析为问答对列表。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result_files = [os.path.join(result_directory, file) for file in os.listdir(result_directory) if file.endswith('.txt')]\n",
    "        all_results = {file: read_result_file(file) for file in result_files}\n",
    "        print(f\"Loaded results from {len(result_files)} files.\")\n",
    "        return all_results\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results from directory {result_directory}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def merge_file_contents(content1, content2):\n",
    "    \"\"\"\n",
    "    简单合并两个文件的内容。\n",
    "    \"\"\"\n",
    "    return content1 + \"\\n\\n\" + content2\n",
    "\n",
    "def merge_and_save_files(result_files, output_directory):\n",
    "    \"\"\"\n",
    "    对指定文件进行两两合并，并输出合并后的文件。\n",
    "    \"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    merged_files = []\n",
    "    \n",
    "    result_file_paths = list(result_files.keys())\n",
    "    for i in range(len(result_file_paths)):\n",
    "        file1_path = result_file_paths[i]\n",
    "        for j in range(i + 1, len(result_file_paths)):\n",
    "            file2_path = result_file_paths[j]\n",
    "            with open(file1_path, 'r', encoding='utf-8') as file1, open(file2_path, 'r', encoding='utf-8') as file2:\n",
    "                content1 = file1.read().strip()\n",
    "                content2 = file2.read().strip()\n",
    "                merged_content = merge_file_contents(content1, content2)\n",
    "                \n",
    "                merged_file_name = f\"merged_{i+1}_{j+1}.txt\"\n",
    "                merged_file_path = os.path.join(output_directory, merged_file_name)\n",
    "                with open(merged_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                    output_file.write(merged_content)\n",
    "                \n",
    "                merged_files.append(merged_file_path)\n",
    "    \n",
    "    return merged_files\n",
    "\n",
    "def parse_query_answer(content):\n",
    "    \"\"\"\n",
    "    解析文档内容为Query和Answer对。\n",
    "    \"\"\"\n",
    "    combined_results = defaultdict(list)\n",
    "    lines = content.split('\\n')\n",
    "    current_query = None\n",
    "    current_answer = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Query:\"):\n",
    "            if current_query:\n",
    "                combined_results[current_query].append(\"\\n\".join(current_answer))\n",
    "            current_query = line\n",
    "            current_answer = []\n",
    "        elif line.startswith(\"Answer:\") and current_query:\n",
    "            current_answer.append(line)\n",
    "        elif current_query and line:\n",
    "            current_answer[-1] += \" \" + line  # Append to the last answer line for multi-line answers\n",
    "    if current_query:\n",
    "        combined_results[current_query].append(\"\\n\".join(current_answer))\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "def combine_answers_by_query(merged_file_path):\n",
    "    \"\"\"\n",
    "    按问题合并答案，将所有相同问题的答案合并在一起。\n",
    "    \"\"\"\n",
    "    combined_results = defaultdict(list)\n",
    "    \n",
    "    with open(merged_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read().strip()\n",
    "        combined_results.update(parse_query_answer(content))\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "def save_combined_results(combined_results, output_file_path):\n",
    "    \"\"\"\n",
    "    保存所有合并后的结果到一个文件中。\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        for query, answers in combined_results.items():\n",
    "            combined_content = f\"{query}\\n\\n\" + \"\\n\\n\".join(answers) + \"\\n\\n\"\n",
    "            file.write(combined_content)\n",
    "    print(f\"Combined results saved to {output_file_path}\")\n",
    "\n",
    "# 使用示例\n",
    "result_directory = \"./A fengmaoyaosu/Results/chouquresults\"\n",
    "merged_result_directory = \"./A fengmaoyaosu/Results/MergedResults\"\n",
    "final_output_directory = \"./A fengmaoyaosu/Results/FinalResults\"\n",
    "\n",
    "# 读取所有问答结果\n",
    "result_files = load_all_results(result_directory)\n",
    "\n",
    "# 两两合并文件内容并保存中间结果\n",
    "merged_files = merge_and_save_files(result_files, merged_result_directory)\n",
    "print(f\"Merged files saved to {merged_result_directory}\")\n",
    "\n",
    "# 处理每个合并后的文件并保存最终结果\n",
    "os.makedirs(final_output_directory, exist_ok=True)\n",
    "for merged_file in merged_files:\n",
    "    combined_results = combine_answers_by_query(merged_file)\n",
    "    output_file_name = f\"final_{os.path.basename(merged_file)}\"\n",
    "    output_file_path = os.path.join(final_output_directory, output_file_name)\n",
    "    save_combined_results(combined_results, output_file_path)\n",
    "print(f\"Final combined results saved to {final_output_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
